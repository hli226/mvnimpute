---
title: "Tutorial_simulated_data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial_simulated_data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>",
  fig.height = 6,
  fig.width = 6
)
```

```{r setup, message = FALSE}
# include the package
library(mvnimpute)
library(tidyverse)
`%notin%` <- Negate(`%in%`)
set.seed(223)
```

To use this package, one needs to pre-process the dataset for some necessary information that is required. This tutorial will present the step-by-step instructions of using this package by an artificial example.

### Data

Here we generate a 10-dimensional multivariate normal data using the **data.gen** function in this package, with 4 subject to missing (MAR) and 4 to interval censoring. In the summary, `NA` denotes the missing data and `NaN` the censored data. Column names indicate the types of the variables, missing, censored or observed, and the position of the variable in the original dataset.

```{r}
p <- 10; m <- 4; n <- 4
mu.vec <- rnorm(p, 5, 0.5)
sample.size <- 2000
V <- clusterGeneration::genPositiveDefMat("eigen", dim = p)

dat <- dat.gen(
  sample.size,
    p,
  mu.vec,
  V$Sigma,
  m,
  n
)


# take a look at the first 5 rows of the data
head(dat$comp.dat, 5)

# take a look at the output of the output list

str(dat)
```

Currently, the **dat.gen** function only supports generating data with interval censored values. The result is a list of 10 including:

* `full.dat`: The full complete data before the missing and censoring information applied.
* `comp.dat`: The incomplete data after the missing and censoring information applied.
* `miss.indx`: The matrix containing the missing index for the missing data. 1 for missing values, 0 for observed values.
* `miss.pos`: The vector indicating the position of the missing variables in the original dataset.
* `miss.point`: The vector containing the cutoff values for the missing data. For the observed data that is $\le$ the cutoff value, the corresponding missing variables are set to be missing.
* `censor.indx`: The matrix containing the censoring index for the censored data. 1 for censored values, 0 otherwise.
* `censor.pos`: The vector indicating the position of the censored variables in the original dataset.
* `C1`: The vector containing the lower limits of the censored values.
* `C2`: The vector containing the upper limits of the censored values.
* `full.pos`: The vector indicating the position of the fully observed variables.

### Missing and censoring information

```{r}
miss.pos <- dat$miss.pos
censor.pos <- dat$censor.pos
miss.indx <- as.data.frame(dat$miss.indx)
censor.indx <- as.data.frame(dat$censor.indx)
censor.val <- list()
censor.val[[1]] <- dat$C1
censor.val[[2]] <- dat$C2
colnames(miss.indx) <- colnames(dat$comp.dat)[grepl("miss", colnames(dat$comp.dat))]
colnames(censor.indx) <- colnames(censor.val[[1]]) <- colnames(censor.val[[2]]) <- colnames(dat$comp.dat)[grepl("censor", colnames(dat$comp.dat))]
miss.no <- apply(miss.indx, 2, sum)
censor.no <- apply(censor.indx, 2, sum)

miss.dat <- data.frame(obs.no = sample.size - miss.no, 
                       miss.no = miss.no,
                       miss.pct = miss.no / sample.size)

censor.dat <- data.frame(obs.no = sample.size - censor.no,
                         censor.no = censor.no,
                         censor.pct = censor.no / sample.size)

## miss variables
miss.dat

## censor variables
censor.dat
```

`miss.indx` and `miss.pos` include the missing index and positions of missing variables.

```{r}
# missing indicators
head(miss.indx)

# positions of missing variables
miss.pos 
```

`censor.indx`, `censor.pos` and `censor.val` include the censoring index, positions of censored variables, and lower and upper limits of censoring. Specifically, `censor.val` is a list of 2, first element is the lower limits , and second is the upper limits.

```{r}
# censoring indicators
head(censor.indx)

# positions of censored variables
censor.pos

# lower limits
head(censor.val[[1]])

# upper limits
head(censor.val[[2]])
```

**NOTE**: The dimension of `miss.indx` should match the length of `miss.pos`, that is the number of missing variables. The dimension of `censor.indx`, and that of `censor.val` should match the length of `censor.pos`, which should be the number of censored variables. They are not necessarily the dimension of the original dataset. The order of `miss.pos` or `censor.pos` does not need to match the order of the corresponding index matrix, **multiple.impute** function will handle it internally.

### Summary plot

```{r, message = FALSE}
# visulizatio tool of the data
visual.plot(dat$comp.dat,
            dat$miss.indx,
            dat$censor.indx)
```

The plot above shows the percentage of missing, censored, and observed values across each variable.

### Multiple imputation

First of all, as the incomplete data includes unobserved data, we need to fill those values up by some simple methods before running multiple imputation. Currently, the **initial.impute** function only incorporates the stochastic regression method in which the unobserved values are generated from the normal distribution with means and variances as the complete-cases means and variances, for the initial stage of filling up the unobserved values.

```{r, message = FALSE}
fil.dat <- initial.impute(dat$comp.dat, miss.indx, miss.pos, censor.indx, censor.pos)

# take a glance at the first few rows
head(fil.dat)
```

In the current algorithm, we use conjugate priors for the normal distribution for performing multiple imputation. We have to specify the prior parameter values and the starting values to initiate the iterative process.

```{r}
# calculate the CC and AC parameter values
params <- calcu.param(dat$comp.dat)

# setup prior parameters and initial values for multiple imputation
prior.param <- list(
  mu.0 = params$AC.mean,
  Lambda.0 = params$CC.cov,
  kappa.0 = 100,
  nu.0 = p * (p + 1) / 2
)

initial.vals <- list(
  mu = params$CC.mean,
  sigma = params$CC.cov
)

```

Prior specifications `prior.param` should be a length of four including:

* `mu.0`: prior mean vector
* `Lambda.0`: prior scale matrix
* `kappa.0`: number of prior measurements
* `nu.0`: degrees of freedom of the prior scale matrix

Starting values `inital.vals` is a list of length two including:

* `mu`: starting values for the mean vector.
* `sigma`: staring values for the covariance matrix.


We run 500 iterations.

For doing multiple imputation, the **multiple.impute** function requires several arguments including:

* `iter`: the number of rounds doing multiple imputation.
* `prior.params`: the parameter specifications for the prior distribution.
* `initial.values`: starting values for the parameters.
* `data`: the complete dataset with unobserved data filled in.
* `miss.index`: matrix including the missing index. 1 for missing, 0 otherwise.
* `miss.pos`: vector indicating the positions of missing variables in the original dataset.
* `censor.index`: matrix including the censoring index. 1 ofr missing, 0 otherwise.
* `censor.pos`: vector indicating the positions of censored variables in the original dataset.
* `censor.values`: matrix (left/right censoring) or list of length two (interval censoring) including the censoring values.
* `censor.type`: typical of censoring, it takes "left", "right", or "interval".

```{r, message = FALSE}
# multiple imputation
iter <- 500
sim.dat <- multiple.impute(
  iter = iter,           # number of iterations
  prior.params = prior.param,    # prior specifications
  initial.values = initial.vals,   # staring values
  data = fil.dat,        # complete data with missing and censored values filled in 
  miss.index = miss.indx,      # missing index matrix
  miss.pos = miss.pos,       # missing variables position vector
  censor.index = censor.indx,    # censoring index matrix
  censor.pos = censor.pos,     # censoring variables position vector
  censor.values = censor.val,     # censoring cutoff values list or matrix
  censor.type = "interval"      # censoring types
)
```


### Diagnostic plots

#### Convergence plots

Mean and Variance convergence plots:

```{r}
par(mfrow = c(1, 2))
conv.plot(sim.dat$simulated.mu, iter, title = "Simulated means vs. iteration")
conv.plot(sim.dat$simulated.sig, iter, title = "Simulated variances vs. iteration")
```

Averaged mean and variance plots:

```{r}
par(mfrow = c(1, 2))
avg.plot(sim.dat$simulated.mu, iter, title = "Averaged simulated means vs. iteration")
avg.plot(sim.dat$simulated.sig, iter, title = "Averaged simulated variances vs. iteration")
```

#### Autocorrelation plots

```{r}
calcu.acf(sim.dat$simulated.mu, 100, plot = TRUE, title = paste(colnames(dat$comp.dat), " mean", sep = ""))
calcu.acf(sim.dat$simulated.sig, 100, plot = TRUE, title = paste(colnames(dat$comp.dat), " variance", sep = ""))
```

The convergence plots show that the algorithm works and converges very fast, while the autocorrelations plots show that the autocorrelations among iterations decay and become negligible very fast.

### Parameters table

Mean and variance biases:

```{r, echo = FALSE}
full.dat.mean <- apply(dat$full.dat, 2, mean)
CC.mean <- params$CC.mean

Gibbs <- seq(0.8 * iter, iter, by = 0.02 * iter)
simulate.mean <- apply(sim.dat$simulated.mu[Gibbs, ], 2, mean)

compare.mean <- data.frame(rbind(full.dat.mean, CC.mean, simulate.mean, mu.vec))
rownames(compare.mean) <- c("full.mean", "CC.mean", "simulated.mean","true.mean")
bias.mean <- sweep(compare.mean, 2, mu.vec)

full.dat.var <- apply(dat$full.dat, 2, var)
CC.var <- params$CC.var

simulate.var <- apply(sim.dat$simulated.sig[Gibbs, ], 2, mean)

compare.var <- data.frame(rbind(full.dat.var, CC.var, simulate.var, diag(V$Sigma)))
rownames(compare.var) <- c("full.variance", "CC.variance", "simulated.variance","true.variance")
bias.variance <- sweep(compare.var, 2, diag(V$Sigma))

bias.mean
bias.variance
```

From the table above, we see the simuated parameters values are quite comparable to the full data parameter values in terms of the biases from the truly specified parameter values.

### Marginal plots

Compare the marginal distributions of the original data with the imputed data from the last iteration:

```{r}
for (i in 1:ncol(dat$comp.dat)) {
  plot(density(na.omit(dat$comp.dat[, i])), main = colnames(dat$comp.dat)[i])
  lines(density(c(sim.dat$imputed.dat[[iter]][, i])), col = 2, lty = 2)
}
