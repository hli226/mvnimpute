---
title: "Tutorial1_Simulated_data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial1_Simulated_data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>",
  fig.align = "center",
  fig.height = 6,
  fig.width = 6
)
```

```{r setup, message = FALSE}
# include the package
library(mvnimpute)
```

To use this package, one needs to prepare the data with the specified format that can be handled by this package. In this tutorial, I will present an example using the artificial data set generated by the data generating function `data.generation` from this package. For the preparation of any arbitrary data set including missing and censored data, please refer to the second vignette using a subset of the NHANES data.

## 1. Data generation

Here we generate a **5-dimensional** multivariate normal data with sample size **2000**, using the *data.generation* function in this package, with two variables subject to missing (MAR) and three variables to interval censoring. 

The `data.generation` function needs several arguments including:

+ `n`: sample size/number of observations of the generated data.
+ `p`: dimensions/number of variables of the generated data.
+ `mu`: specified mean vector for the generated data.
+ `Sigma`: covariance matrix for the generated data.
+ `miss.pos`: indexes of the variables that have missing values
+ `miss.percent`: missing percentages of the variables that have missing values.
+ `miss.type`: missing data mechanisms. It has options `"MCAR"` and `"MAR"`. Default is `"MCAR"`.
+ `censor.pos`: indexes of the variables that have censored values
+ `censor.percent1`: lower percentiles of the values that are not missing for censored variables. This quantity is used for determining the lower limit of the censoring interval.
+ `censor.percent2`: upper percentiles of the values that are not missing for censored variables. This quantity is used for determining the upper limit of the censoring interval.
+ `censor.type`: censored data types. It has options `"interval"`, `"left"` and `"right"`. Default is `"interval"`.

```{r}
#######################
# Data specifications #
#######################
set.seed(133)
sample.size <- 2000; p <- 5
mu.vec <- rnorm(p, 5, 0.5)

# create a positive definite covariance matrix
mat <- matrix(rnorm(p^2), ncol = p)
V <- t(mat) %*% mat

# missing and censoring information
miss.pos <- c(2, 3)
miss.percent <- c(0.21, 0.38)

## censoring
censor.pos <- c(3, 4, 5)
censor.percent1 <- c(0.22, 0.54, 0.2)
censor.percent2 <- c(0.40, 0.88, 0.29)
```

By specification, we set $y_2$ and $y_3$ as the variables with missing values under the MAR mechanism, that is, the missing data depend only on a fully observed variable. The missing percentages are 0.21 and 0.38, respectively. $y_3$, $y_4$ and $y_5$ are the variables with interval-censored values. Thus $y_3$ have both missing and censored values. 

We consider missing data as a special case of "interval censoring", with two limits of the censoring interval as $-\infty$ and $\infty$, respectively. Specifically, we generate a pair of values for each single data point in the following minor. Denote the generated values as $X_1$ and $X_2$, respectively, the data is generated is the following manner:

+ If a value is **observed**, we set $X_1 = X_2$.
+ If a value is **missing**, we take $-10^{10}$ and $-10^{10}$ as proxies for $-\infty$ and $\infty$, and set $X_1 = -10^{10}$ and $X_2 = 10^{10}$.
+ If a values is **censored**, we set those limits as infinite or finite values according to the censoring type.

```{r}
# Data generation
set.seed(133)
dat <- data.generation(
  n = sample.size,
  p = p,
  mu = mu.vec,
  Sigma = V,
  miss.pos = miss.pos,
  miss.percent = miss.percent,
  miss.type = "MAR",
  censor.pos = censor.pos,
  censor.percent1 = censor.percent1,
  censor.percent2 = censor.percent2,
  censor.type = "interval"
)
```

There are three outputs include 

+ `full.data`: a full data without missing and censoring information applied.
+ `data`: a list of two elements is generated for containing the two sets of values.
+ `indicator`: a data type indicator matrix that indicates the corresponding data type. It would only be used for visualization purpose.

### data type indicator matrix

Let us see the first few lines of the generated data type indicator matrix and the data:

```{r, echo = FALSE}
# take a look at the first 5 lines of the data type indicator matrix
head(dat$indicator, 5)
```

This data type indicator matrix has the same dimension as the desired data (that is to say, the data type indicator matrix is also $`r sample.size` \times `r p`$). 0 indicates the corresponding value is missing, 1 indicates the corresponding value is observed, and 2 is indicator for censored values. 

### lower limits

```{r, echo = FALSE}
# take a look at the first 5 lines of the two matrices
head(dat$data[[1]], 5)

```

### upper limits

```{r}
head(dat$data[[2]], 5)
```

<!-- This function actually generates a pair of values, say $X_{ll}$ and $X_{ul}$ for each data point. Each value of the two is stored in a matrix that has the same dimension as the desired data, and each matrix is an element of a list that contains the data. Specifically, we generate data in the following way: -->

<!-- + For **observed** values (as 1 in the data type indicator matrix), we set $X_{ll} = X_{ul}$. -->
<!-- + For **missing** values (as 0 in the data type indicator matrix), we consider those values as special cases of the interval censored values, with two limit values as $-\infty$ and $\infty$. We take $-10^{10}$ and $10^{10}$ as proxies for $-\infty$ and $\infty$, respectively. -->
<!-- + For **censored** values (as 2 in the data type indicator matrix), we set $X_{ll}$ and $X_{ul}$ to the values corresponding to the specified censoring type. For example, if the values are *interval* censored, we set $X_{ll} > -10^{10}$ and $X_{ul} < 10^{10}$, which means that both limits are finite numbers; if the values are *right* censored, we set $X_{ll} > -10^{10}$ and $X_{ul} = 10^{10}$, which means that the left limit is finite, while the right limit is infinite; if the values are *left* censored, we set $X_{ul} < 10^{10}$ and $X_{ll} = -10^{10}$ -->

In the generated data, we see that the first and fifth values of $y_2$ are missing, as indicated in the data type matrix by 0, The corresponding values in the generated data are $-10^{10}$ and $10^{10}$, respectively. The pair for the third observation for $y_3$ are different from each other and are finite, suggesting that value is interval censored, as indicted by 2 in the data type matrix.

## 2. Data visualization

Next, we see a plot that graphically shows the percentages of the missing, observed and censored values in the generated data using the function *visual.plot*. This function requires only one argument, that is the data type indicator matrix generated in the previous data generation step.

```{r}
visual.plot(dat$indicator)
```

## 3. Multiple imputation

The data generated above is a list of two containing the limits information of the data $X_{ll}$ and $X_{ul}$ in two matrices. We will use those information in the imputation process, and create a new matrix to including the imputed data set. We have a function `single imputation` for making up the incomplete data for the multiple imputation. Currently, the missing values are generated from the normal distribution with the complete-case mean and variance and censored values from the truncated normal distribution with complete-case parameters. The major function `multiple.imputation` uses the `single.imputation` function as the first step, thus we do not need to run `single.imputation` function separately.

We use the Gibbs Sampling approach with Normal-inverse-Wishart conjugate prior distribution for the mean and covariance matrix. Thus we need to specify the prior parameter values and the starting values. They should each be a list with certain formats as shown below.

Prior specifications `prior` should be a length of four including:

* `mu.0`: prior mean vector
* `Lambda.0`: prior scale matrix
* `kappa.0`: number of prior measurements
* `nu.0`: degrees of freedom of the prior scale matrix

Starting values `starting` is a list of length two including:

* `mu`: starting values for the mean vector.
* `sigma`: staring values for the covariance matrix.


```{r}
# calculate the CC and AC parameter values
params <- param.calc(dat$data)

# setup prior parameters and starting values for multiple imputation
prior <- list(
  mu.0 = params$AC.mean,
  Lambda.0 = params$CC.cov,
  kappa.0 = 100,
  nu.0 = p * (p + 1) / 2
)

starting <- list(
  mu = params$CC.mean,
  sigma = params$CC.cov
)

```

We use the complete-case mean and covariance matrix as the staring values and we run the Gibbs sampling for `r iter`iterations. The *multiple.imputation* function implements the multiple imputation algorithm, it requires five arguments including:

+ `data`: the list of two generated in the data generation step that include the missing and censoring information.
+ `prior.params`: the list of priors specifications that has the fixed format as described above.
+ `starting.values`: the starting values for initializing the multiple imputation algorithm.
+ `iter`: rounds of perfoming multiple imputation.
+ `details`: logical variable to specify whether the running status is printed.

```{r, message = FALSE}
# multiple imputation rounds
iter <- 500

# multiple imputation
sim.dat <- multiple.imputation(
  data = dat$data,
  prior.params = prior,
  starting.values = starting,
  iter = iter,
  details = FALSE
)
```


## 4. Diagnostic plots

### Convergence plots

Function *conv.plot* draws the trace plot of simulated parameter values

```{r}
conv.plot(sim.dat$simulated.mu, iter, title = "Simulated means vs. iteration")
conv.plot(sim.dat$simulated.sig, iter, title = "Simulated variances vs. iteration")
```

### Autocorrelation plots

Function *acf.calc* calculates the autocorrelation values :

```{r}
acf.calc(sim.dat$simulated.mu, 100, plot = TRUE, title = paste(colnames(dat$full.data), " mean", sep = ""))
acf.calc(sim.dat$simulated.sig, 100, plot = TRUE, title = paste(colnames(dat$full.data), " variance", sep = ""))
```

The convergence plots show that the algorithm works and converges very fast, while the autocorrelations plots show that the autocorrelations among iterations decay and become negligible very fast.

## 5. Comparison of parameters

We choose several iterations starting from `r 0.8 * iter` to the end of the simulation with `r 0.04 * iter` iterations in between. We pool the parameters values from those iterations and compare those values will full data parameters, complete-case parameters and the specified values.

The table below presents the biases of the parameter values from the specified parameter values.

```{r, echo = FALSE}
full.dat.mean <- apply(dat$full.data, 2, mean)
CC.mean <- params$CC.mean

Gibbs <- seq(0.8 * iter, iter, by = 0.04 * iter)
simulated.mean <- apply(sim.dat$simulated.mu[Gibbs, ], 2, mean)

compare.mean <- data.frame(rbind(full.dat.mean, CC.mean, simulated.mean, mu.vec))
rownames(compare.mean) <- c("full.mean", "CC.mean", "simulated.mean","true.mean")
bias.mean <- sweep(compare.mean, 2, mu.vec)

full.dat.var <- apply(dat$full.dat, 2, var)
CC.var <- diag(params$CC.cov)

simulate.var <- apply(sim.dat$simulated.sig[Gibbs, ], 2, mean)

compare.var <- data.frame(rbind(full.dat.var, CC.var, simulate.var, diag(V)))
rownames(compare.var) <- c("full.variance", "CC.variance", "simulated.variance","true.variance")
bias.variance <- sweep(compare.var, 2, diag(V))
```

### 5.1 Mean

```{r}
bias.mean
```

`full.mean`, `CC.mean`, `simulated.mean` and `true.mean` stand from the mean of the full data, the mean of the complete-case data with missing and censoring information removed, the mean of the simulated data from the Gibbs sampler and the specified mean.

### 5.2 Variance

```{r}
bias.variance
```

`full.variance`, `CC.variance`, `simulated.variance` and `true.variance` stand from the variance of the full data, the variance of the complete-case data with missing and censoring information removed, the variance of the simulated data from the Gibbs sampler and the specified mean.

From the table above, we see the simulated parameters values are quite comparable to the full data parameter values in terms of the biases from the truly specified parameter values.

## 6. Marginal density plots

The plots below compares the marginal density plots of the original full data and the imputed data from the last iteration of multiple imputation

```{r}

for (i in 1:5) {
  
  plot(density(dat$full.dat[, i]), main = colnames(dat$full.data)[i])
  lines(density(sim.dat$impute[[iter]][, i]), col = 2, lty = 2)
  
}
```


